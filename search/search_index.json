{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Beyond the Basics: Istio and IBM Cloud Kubernetes Service","text":"<p>Istio is an open platform to connect, secure, control and observe microservices, also known as a service mesh, on cloud platforms such as Kubernetes in IBM Cloud Kubernetes Service and VMs. With Istio, You can manage network traffic, load balance across microservices, enforce access policies, verify service identity, secure service communication and observe what exactly is going on with your services.</p> <p>YouTube: Istio Service Mesh Explained:</p> <p></p> <p>In this course, you can see how to install Istio alongside microservices for a simple mock app called Guestbook. When you deploy Guestbook's microservices into an IBM Cloud Kubernetes Service cluster where Istio is installed, you can choose to inject the Istio Envoy sidecar proxies in the pods of certain microservices.</p> <p>Estimated completion time: 2 hours</p>"},{"location":"#objectives","title":"Objectives","text":"<p>After you complete this course, you'll be able to:</p> <ul> <li>Download and install Istio in your cluster</li> <li>Deploy the Guestbook sample app</li> <li>Use metrics, logging and tracing to observe services</li> <li>Set up the Istio Ingress Gateway</li> <li>Perform simple traffic management, such as A/B tests and canary deployments</li> <li>Secure your service mesh</li> <li>Enforce policies for your microservices</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>You must you must have a Pay-As-You-Go, or Subscription IBM Cloud account to complete all the modules in this course.</p> <p>You must have already created a Standard 1.16+ cluster in IBM Cloud Kubernetes Service. FREE Cluster is not supported for this lab</p> <p>You should have a basic understanding of containers, IBM Cloud Kubernetes Service, and Istio. If you have no experience with those, take the following courses:</p> <ol> <li>Get started with Kubernetes and IBM Cloud Kubernetes Service</li> <li>Get started with Istio and IBM Cloud Kubernetes Service</li> </ol>"},{"location":"#workshop-setup","title":"Workshop setup","text":"<ul> <li>Exercise 1 - Accessing a Kubernetes cluster with IBM Cloud Kubernetes Service</li> <li>Exercise 2 - Installing Istio</li> <li>Exercise 3 - Deploying Guestbook sample application</li> </ul>"},{"location":"#creating-a-service-mesh-with-istio","title":"Creating a service mesh with Istio","text":"<ul> <li>Exercise 4 - Observe service telemetry: metrics and tracing</li> <li>Exercise 5 - Expose the service mesh with the Istio Ingress Gateway</li> <li>Exercise 6 - Perform traffic management</li> <li>Exercise 7 - Secure your service mesh</li> </ul>"},{"location":"#cleaning-up-the-workshop","title":"Cleaning up the Workshop","text":"<p>Script to uninstall <code>ibmcloud</code> CLI: clean_your_local_machine.sh and unset <code>KUBECONFIG</code>.</p> <p>Script to delete Istio and Guestbook: clean_your_k8s_cluster.sh.</p>"},{"location":"SUMMARY/","title":"Table of contents","text":""},{"location":"SUMMARY/#about-this-workshop","title":"About this workshop","text":"<ul> <li>Overview</li> </ul>"},{"location":"SUMMARY/#workshop-setup","title":"Workshop setup","text":"<ul> <li>Exercise 1 - Accessing a Kubernetes cluster with IBM Cloud Kubernetes Service</li> <li>Exercise 2 - Installing Istio</li> <li>Exercise 3 - Deploying Guestbook sample application</li> </ul>"},{"location":"SUMMARY/#creating-a-service-mesh-with-istio","title":"Creating a service mesh with Istio","text":"<ul> <li>Exercise 4 - Observe service telemetry: metrics and tracing</li> <li>Exercise 5 - Expose the service mesh with the Istio Ingress Gateway</li> <li>Exercise 6 - Perform traffic management</li> <li>Exercise 7 - Secure your service mesh</li> </ul>"},{"location":"exercise-1/","title":"Exercise 1 - Accessing a Kubernetes cluster with IBM Cloud Kubernetes Service","text":"<p>You must already have a cluster created. Your cluster must have 3 or more worker nodes with at least 4 cores and 16GB RAM, and run Kubernetes version 1.16 or later.</p>"},{"location":"exercise-1/#install-ibm-cloud-kubernetes-service-command-line-utilities","title":"Install IBM Cloud Kubernetes Service command line utilities","text":"<ol> <li> <p>Download and install the required CLI tools.</p> <pre><code>curl -sL https://ibm.biz/idt-installer | bash\n</code></pre> </li> <li> <p>Log in to the IBM Cloud CLI. (If you have a federated account, include the <code>--sso</code> flag.)</p> <pre><code>ibmcloud login\n</code></pre> </li> </ol>"},{"location":"exercise-1/#access-your-cluster","title":"Access your cluster","text":"<p>Learn how to set the context to work with your cluster by using the <code>kubectl</code> CLI, access the Kubernetes dashboard, and gather basic information about your cluster.</p> <ol> <li> <p>Set the context for your cluster in your CLI. Every time you log in to the IBM Cloud Kubernetes Service CLI to work with the cluster, you must run these commands to set the path to the cluster's configuration file as a session variable. The Kubernetes CLI uses this variable to find a local configuration file and certificates that are necessary to connect with the cluster in IBM Cloud.</p> <p>a. List the available clusters.</p> <pre><code>ibmcloud ks clusters\n</code></pre> <p>b. Set an environment variable for your cluster name:</p> <pre><code>export MYCLUSTER=&lt;your_cluster_name&gt;\n</code></pre> <p>c. Download the configuration file and certificates for your cluster using the <code>cluster-config</code> command.</p> <pre><code>ibmcloud ks cluster config --cluster $MYCLUSTER\n</code></pre> </li> <li> <p>Get basic information about your cluster and its worker nodes. This information can help you manage your cluster and troubleshoot issues.</p> <p>a.  View details of your cluster.</p> <pre><code>ibmcloud ks cluster get --cluster $MYCLUSTER\n</code></pre> <p>b.  Verify the worker nodes in the cluster.</p> <pre><code>ibmcloud ks workers --cluster $MYCLUSTER\n</code></pre> </li> <li> <p>Validate access to your cluster by viewing the nodes in the cluster.</p> <pre><code>kubectl get nodes\n</code></pre> </li> </ol>"},{"location":"exercise-1/#clone-the-lab-repo","title":"Clone the lab repo","text":"<ol> <li> <p>From your command line, run:</p> <pre><code>git clone https://github.com/IBM/istio101\n\ncd istio101/docs\n</code></pre> <p>This is the working directory for the workshop. You will use the example <code>.yaml</code> files that are located in the <code>workshop/plans</code> directory in the following exercises.</p> </li> </ol>"},{"location":"exercise-1/#continue-to-exercise-2-installing-istio","title":"Continue to Exercise 2 - Installing Istio","text":""},{"location":"exercise-2/","title":"Exercise 2 - Installing Istio on IBM Cloud Kubernetes Service","text":"<p>In this module, you will use the Managed Istio add-on to install Istio on your cluster.</p> <p>Managed Istio is available as part of IBM Cloud\u2122 Kubernetes Service. The service provides seamless installation of Istio, automatic updates and lifecycle management of control plane components, and integration with platform logging and monitoring tools.</p> <ol> <li>Download the <code>istioctl</code> CLI and add it to your PATH:</li> </ol> <pre><code>curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.11.4 sh -\n</code></pre> <pre><code>export PATH=$PWD/istio-1.11.4/bin:$PATH\n</code></pre> <ol> <li> <p>Enable Managed Istio on your IKS cluster:</p> <pre><code>ibmcloud ks cluster addon enable istio --cluster $MYCLUSTER\n</code></pre> </li> <li> <p>The install can take up to 10 minutes. Ensure the corresponding pods are all in <code>Running</code> state before you continue.</p> <pre><code>kubectl get pods -n istio-system\n</code></pre> <p>Sample output:</p> <pre><code>NAME                                     READY   STATUS    RESTARTS   AGE\nistio-egressgateway-6c966469cc-52t6f    1/1     Running   0          69s\nistio-egressgateway-6c966469cc-qq5qd    1/1     Running   0          55s\nistio-ingressgateway-7698c7b4f4-69c24   1/1     Running   0          68\nistio-ingressgateway-7698c7b4f4-qttzh   1/1     Running   0          54s\nistiod-cbb98c74d-2wvql                  1/1     Running   0          54s\nistiod-cbb98c74d-kcr4d                  1/1     Running   0          67s\n</code></pre> </li> </ol> <p>NOTE Before you continue, make sure all the pods are deployed and either in the <code>Running</code> or <code>Completed</code> state. If they're in <code>pending</code> state, wait a few minutes to let the installation and deployment finish.</p> <ol> <li> <p>Check the version of your Istio:</p> <pre><code>istioctl version\n</code></pre> <p>Sample output:</p> <pre><code>client version: 1.11.4\ncontrol plane version: 1.11.4\ndata plane version: 1.11.4 (4 proxies)\n</code></pre> <p>Congratulations! You successfully installed Istio into your cluster.</p> </li> </ol>"},{"location":"exercise-2/#continue-to-exercise-3-deploy-guestbook-with-istio-proxy","title":"Continue to Exercise 3 - Deploy Guestbook with Istio Proxy","text":""},{"location":"exercise-3/","title":"Exercise 3 - Deploy the Guestbook app with Istio Proxy","text":"<p>The Guestbook app is a sample app for users to leave comments. It consists of a web front end, Redis master for storage, and a replicated set of Redis slaves. We will also integrate the app with Watson Tone Analyzer which detects the sentiment in users' comments and replies with emoticons.</p> <p></p>"},{"location":"exercise-3/#download-the-guestbook-app","title":"Download the Guestbook app","text":"<ol> <li> <p>Clone the Guestbook app into the <code>workshop</code> directory.</p> <pre><code>git clone https://github.com/IBM/guestbook\n</code></pre> </li> <li> <p>Navigate into the app directory.</p> <pre><code>cd guestbook/v2\n</code></pre> </li> </ol>"},{"location":"exercise-3/#enable-the-automatic-sidecar-injection-for-the-default-namespace","title":"Enable the automatic sidecar injection for the default namespace","text":"<p>In Kubernetes, a sidecar is a utility container in the pod, and its purpose is to support the main container. For Istio to work, Envoy proxies must be deployed as sidecars to each pod of the deployment. There are two ways of injecting the Istio sidecar into a pod: manually using the istioctl CLI tool or automatically using the Istio sidecar injector. In this exercise, we will use the automatic sidecar injection provided by Istio.</p> <ol> <li> <p>Annotate the default namespace to enable automatic sidecar injection:</p> <pre><code>kubectl label namespace default istio-injection=enabled\n</code></pre> </li> <li> <p>Validate the namespace is annotated for automatic sidecar injection:</p> <pre><code>kubectl get namespace -L istio-injection\n</code></pre> <p>Sample output:</p> <pre><code>NAME             STATUS   AGE    ISTIO-INJECTION\ndefault          Active   271d   enabled\nistio-system     Active   5d2h\n...\n</code></pre> </li> </ol>"},{"location":"exercise-3/#create-a-redis-database","title":"Create a Redis database","text":"<p>The Redis database is a service that you can use to persist the data of your app. The Redis database comes with a master and slave modules.</p> <ol> <li> <p>Create the Redis controllers and services for both the master and the slave.</p> <pre><code>kubectl create -f redis-master-deployment.yaml\nkubectl create -f redis-master-service.yaml\nkubectl create -f redis-slave-deployment.yaml\nkubectl create -f redis-slave-service.yaml\n</code></pre> </li> <li> <p>Verify that the Redis controllers for the master and the slave are created.</p> <pre><code>kubectl get deployment\n</code></pre> <p>Output:</p> <pre><code>NAME           READY   UP-TO-DATE   AVAILABLE   AGE\nredis-master   1/1     1            1           2m16s\nredis-slave    2/2     2            2           2m15s\n</code></pre> </li> <li> <p>Verify that the Redis services for the master and the slave are created.</p> <pre><code>kubectl get svc\n</code></pre> <p>Output:</p> <pre><code>NAME           TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE\nredis-master   ClusterIP      172.21.85.39    &lt;none&gt;          6379/TCP       5d\nredis-slave    ClusterIP      172.21.205.35   &lt;none&gt;          6379/TCP       5d\n</code></pre> </li> <li> <p>Verify that the Redis pods for the master and the slave are up and running.</p> <pre><code>kubectl get pods\n</code></pre> <p>Output:</p> <pre><code>NAME                            READY     STATUS    RESTARTS   AGE\nredis-master-4sswq              2/2       Running   0          5d\nredis-slave-kj8jp               2/2       Running   0          5d\nredis-slave-nslps               2/2       Running   0          5d\n</code></pre> </li> </ol>"},{"location":"exercise-3/#install-the-guestbook-app","title":"Install the Guestbook app","text":"<ol> <li> <p>Inject the Istio Envoy sidecar into the guestbook pods, and deploy the Guestbook app on to the Kubernetes cluster. Deploy both the v1 and v2 versions of the app:</p> <pre><code>kubectl apply -f ../v1/guestbook-deployment.yaml\nkubectl apply -f guestbook-deployment.yaml\n</code></pre> <p>These commands deploy the Guestbook app on to the Kubernetes cluster. Since we enabled automation sidecar injection, these pods will be also include an Envoy sidecar as they are started in the cluster. Here we have two versions of deployments, a new version (<code>v2</code>) in the current directory, and a previous version (<code>v1</code>) in a sibling directory. They will be used in future sections to showcase the Istio traffic routing capabilities.</p> </li> <li> <p>Create the guestbook service.</p> <pre><code>kubectl create -f guestbook-service.yaml\n</code></pre> </li> <li> <p>Verify that the service was created.</p> <pre><code>kubectl get svc\n</code></pre> <p>Output:</p> <pre><code>NAME           TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE\nguestbook      LoadBalancer   172.21.36.181   169.61.37.140   80:32149/TCP   5d\n...\n</code></pre> </li> <li> <p>Verify that the pods are up and running.</p> <pre><code>kubectl get pods\n</code></pre> <p>Sample output:</p> <pre><code>NAME                            READY   STATUS    RESTARTS   AGE\nguestbook-v1-98dd9c654-dz8dq    2/2     Running   0          30s\nguestbook-v1-98dd9c654-mgfv6    2/2     Running   0          30s\nguestbook-v1-98dd9c654-x8gxx    2/2     Running   0          30s\nguestbook-v2-8689f6c559-5ntgv   2/2     Running   0          28s\nguestbook-v2-8689f6c559-fpzb7   2/2     Running   0          28s\nguestbook-v2-8689f6c559-wqbnl   2/2     Running   0          28s\nredis-master-577bc6fbb-zh5v8    2/2     Running   0          4m47s\nredis-slave-7779c6f75b-bshvs    2/2     Running   0          4m46s\nredis-slave-7779c6f75b-nvsd6    2/2     Running   0          4m46s\n</code></pre> <p>Note that each guestbook pod has 2 containers in it. One is the guestbook container, and the other is the Envoy proxy sidecar.</p> </li> </ol>"},{"location":"exercise-3/#use-watson-tone-analyzer-optional","title":"Use Watson Tone Analyzer (Optional)","text":"<p>Watson Tone Analyzer detects the tone from the words that users enter into the Guestbook app. The tone is converted to the corresponding emoticons.</p> <ol> <li> <p>Create Watson Tone Analyzer in your account.</p> <pre><code>ibmcloud resource service-instance-create my-tone-analyzer-service tone-analyzer lite us-south\n</code></pre> </li> <li> <p>Create the service key for the Tone Analyzer service. This command should output the credentials you just created. You will need the value for apikey &amp; url later.</p> <pre><code>ibmcloud resource service-key-create tone-analyzer-key Manager --instance-name my-tone-analyzer-service\n</code></pre> </li> <li> <p>If you need to get the service-keys later, you can use the following command:</p> <pre><code>ibmcloud resource service-key tone-analyzer-key\n</code></pre> </li> <li> <p>Open the <code>analyzer-deployment.yaml</code> and find the env section near the end of the file. Replace <code>YOUR_API_KEY</code> with your own API key, and replace <code>YOUR_URL</code> with the url value you saved before. YOUR_URL should look something like <code>https://gateway.watsonplatform.net/tone-analyzer/api</code>. Save the file.</p> </li> <li> <p>Deploy the analyzer pods and service, using the <code>analyzer-deployment.yaml</code> and <code>analyzer-service.yaml</code> files found in the <code>guestbook/v2</code> directory. The analyzer service talks to Watson Tone Analyzer to help analyze the tone of a message. Ensure you are still in the <code>guestbook/v2</code> directory.</p> <pre><code>kubectl apply -f analyzer-deployment.yaml\nkubectl apply -f analyzer-service.yaml\n</code></pre> </li> </ol> <p>Great! Your guestbook app is up and running. In Exercise 4, you'll be able to see the app in action by directly accessing the service endpoint. You'll also be able to view Telemetry data for the app.</p>"},{"location":"exercise-3/#continue-to-exercise-4-telemetry","title":"Continue to Exercise 4 - Telemetry","text":""},{"location":"exercise-4/","title":"Exercise 4 - Observe service telemetry: metrics and tracing","text":""},{"location":"exercise-4/#challenges-with-microservices","title":"Challenges with microservices","text":"<p>We all know that microservice architecture is the perfect fit for cloud native applications and it increases the delivery velocities greatly. Envision you have many microservices that are delivered by multiple teams, how do you observe the the overall platform and each of the service to find out exactly what is going on with each of the services?  When something goes wrong, how do you know which service or which communication among the few services are causing the problem?</p>"},{"location":"exercise-4/#istio-telemetry","title":"Istio telemetry","text":"<p>Istio's tracing and metrics features are designed to provide broad and granular insight into the health of all services. Istio's role as a service mesh makes it the ideal data source for observability information, particularly in a microservices environment. As requests pass through multiple services, identifying performance bottlenecks becomes increasingly difficult using traditional debugging techniques. Distributed tracing provides a holistic view of requests transiting through multiple services, allowing for immediate identification of latency issues. With Istio, distributed tracing comes by default. This will expose latency, retry, and failure information for each hop in a request.</p> <p>You can read more about how Istio mixer enables telemetry reporting.</p>"},{"location":"exercise-4/#configure-istio-to-receive-telemetry-data","title":"Configure Istio to receive telemetry data","text":"<ol> <li>Enable Istio monitoring dashboards, by running these two commands:</li> </ol> <pre><code>kubectl patch cm managed-istio-custom -n ibm-operators --type='json' -p='[{\"op\": \"add\", \"path\": \"/data/istio-monitoring\", \"value\":\"true\"}]'\n</code></pre> <pre><code>kubectl annotate iop -n ibm-operators managed-istio --overwrite version=\"custom-applied-at: $(date)\"\n</code></pre> <ol> <li> <p>Verify that the Grafana, Prometheus, Kiali and Jaeger add-ons were installed successfully. All add-ons are installed into the <code>istio-system</code> namespace.</p> <pre><code>kubectl get services -n istio-system\n</code></pre> </li> <li> <p>Obtain the guestbook endpoint to access the guestbook.</p> <p>You can access the guestbook via the external IP for your service as guestbook is deployed as a load balancer service. Get the EXTERNAL-IP of the guestbook service via output below:</p> <pre><code>kubectl get service guestbook -n default\n</code></pre> <p>Go to this external ip address in the browser to try out your guestbook. This service will route you to either v1 or v2, at random. If you wish to see a different version, you'll need to do a hard refresh (<code>cmd + shift + r</code> on a mac, or <code>ctrl + f5</code> on a PC). Alternatively, you can <code>curl</code> the address.</p> </li> </ol> <p></p> <ol> <li> <p>Generate a small load to the app, replacing guestbook_IP with the EXTERNAL-IP.</p> <pre><code>for i in {1..40}; do sleep 0.2; curl -I http://&lt;guestbook_IP&gt;/; done\n</code></pre> </li> </ol>"},{"location":"exercise-4/#view-guestbook-telemetry-data","title":"View guestbook telemetry data","text":""},{"location":"exercise-4/#jaeger","title":"Jaeger","text":"<ol> <li> <p>Launch the Jaeger dashboard:</p> <pre><code>istioctl dashboard jaeger\n</code></pre> </li> <li> <p>From the Services menu, select either the guestbook or analyzer service.</p> </li> <li>Scroll to the bottom and click on Find Traces button to see traces.</li> <li>Use Ctrl-C in the terminal to exit the port-foward when you are done.</li> </ol> <p>Read more about Jaeger</p>"},{"location":"exercise-4/#grafana","title":"Grafana","text":"<ol> <li>Create a secret which will be used to set the login credentials for Grafana</li> </ol> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: grafana\n  namespace: istio-system\ntype: Opaque\ndata:\n  username: \"YWRtaW4=\"\n  passphrase: \"YWRtaW4=\"\nEOF\n</code></pre> <ol> <li> <p>Wait 2 minutes for the secret to be picked up and then launch the dashboard:</p> <pre><code>istioctl dashboard grafana\n</code></pre> </li> </ol> <p></p> <ol> <li>Log in using <code>admin</code> for both username and password.</li> <li> <p>Navigate to the <code>Istio Service Dashboard</code> by clicking on the Home menu on the top left, then Istio, then Istio Service Dashboard.</p> </li> <li> <p>Select guestbook in the Service drop down.</p> </li> <li> <p>In a different tab, visit the guestbook application and refresh the page multiple times to generate some load, or run the load script you used previously. Switch back to the Grafana tab.</p> </li> <li> <p>Use Ctrl-C in the terminal to exit the port-foward when you are done.</p> </li> </ol> <p>This Grafana dashboard provides metrics for each workload. Explore the other dashboard provided as well.</p> <p>Read more about Grafana.</p>"},{"location":"exercise-4/#prometheus","title":"Prometheus","text":"<ol> <li> <p>Establish port forwarding from local port 9090 to the Prometheus instance.</p> <pre><code>istioctl dashboard prometheus\n</code></pre> </li> </ol> <p></p> <ol> <li> <p>In the \u201cExpression\u201d input box, enter: <code>istio_request_bytes_count</code>. Click Execute and then select Graph.</p> </li> <li> <p>Then try another query: <code>istio_requests_total{destination_service=\"guestbook.default.svc.cluster.local\", destination_version=\"2.0\"}</code></p> </li> <li> <p>Use Ctrl-C in the terminal to exit the port-foward when you are done.</p> </li> </ol>"},{"location":"exercise-4/#kiali","title":"Kiali","text":"<p>Kiali is an open-source project that installs on top of Istio to visualize your service mesh. It provides deeper insight into how your microservices interact with one another, and provides features such as circuit breakers and request rates for your services</p> <ol> <li>Create a secret which will be used to set the login credentials for Kiali</li> </ol> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: kiali\n  namespace: istio-system\n  labels:\n    app: kiali\ntype: Opaque\ndata:\n  username: \"YWRtaW4=\"\n  passphrase: \"YWRtaW4=\"\nEOF\n</code></pre> <ol> <li> <p>Establish port forwarding from local port 20001 to the Kiali instance.</p> <pre><code>istioctl dashboard kiali\n</code></pre> </li> </ol> <p></p> <ol> <li>Login with <code>admin</code> for both username and password.</li> <li>Select Graph and then choose <code>default</code> namespace. You should see a visual service graph of the various services in your Istio mesh.</li> <li>Use the <code>Edge Labels</code> dropdown and select <code>Traffic rate per second</code> to see the request rates as well.</li> <li>Kiali has a number of views to help you visualize your services. Click through the vairous tabs to explore the service graph, and the various views for workloads, applications, and services.</li> </ol>"},{"location":"exercise-4/#understand-what-happened","title":"Understand what happened","text":"<p>Although Istio proxies are able to automatically send spans, they need some hints to tie together the entire trace. Apps need to propagate the appropriate HTTP headers so that when the proxies send span information to Zipkin or Jaeger, the spans can be correlated correctly into a single trace.</p> <p>In the example, when a user visits the Guestbook app, the HTTP request is sent from the guestbook service to Watson Tone Analyzer. In order for the individual spans of guestbook service and Watson Tone Analyzer to be tied together, we have modified the guestbook service to extract the required headers (x-request-id, x-b3-traceid, x-b3-spanid, x-b3-parentspanid, x-b3-sampled, x-b3-flags, x-ot-span-context) and forward them onto the analyzer service when calling the analyzer service from the guestbook service. The change is in the <code>v2/guestbook/main.go</code>. By using the <code>getForwardHeaders()</code> method, we are able to extract the required headers, and then we use the required headers further when calling the analyzer service via the <code>getPrimaryTone()</code> method.</p>"},{"location":"exercise-4/#questions","title":"Questions","text":"<ol> <li> <p>Does a user need to modify their app to get metrics for their apps?   A: 1. Yes 2. No. (2 is correct)</p> </li> <li> <p>Does a user need to modify their app to get distributed tracing for their app to work properly? A: 1. Yes 2. No. (1 is correct)</p> </li> <li> <p>What distributed tracing system does Istio support by default?  A: 1. Zipkin 2. Kibana 3. LogStash 4. Jaeger. (1 and 4 are correct)</p> </li> </ol>"},{"location":"exercise-4/#continue-to-exercise-5-expose-the-service-mesh-with-the-istio-ingress-gateway","title":"Continue to Exercise 5 - Expose the service mesh with the Istio Ingress Gateway","text":""},{"location":"exercise-5/","title":"Exercise 5 - Expose the service mesh with the Istio Ingress Gateway","text":"<p>The components deployed on the service mesh by default are not exposed outside the cluster. External access to individual services so far has been provided by creating an external load balancer or node port on each service.</p> <p>An Ingress Gateway resource can be created to allow external requests through the Istio Ingress Gateway to the backing services.</p> <p></p>"},{"location":"exercise-5/#expose-the-guestbook-app-with-ingress-gateway","title":"Expose the Guestbook app with Ingress Gateway","text":"<ol> <li>Configure the guestbook default route with the Istio Ingress Gateway. The <code>guestbook-gateway.yaml</code> file is in this repository (istio101) in the <code>workshop/plans</code> directory.</li> </ol> <pre><code>cd ../../plans\nkubectl create -f guestbook-gateway.yaml\n</code></pre> <ol> <li>Get the EXTERNAL-IP of the Istio Ingress Gateway.</li> </ol> <pre><code>kubectl get service istio-ingressgateway -n istio-system\n</code></pre> <p>Output:</p> <pre><code>NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                                       AGE\nistio-ingressgateway   LoadBalancer   172.21.254.53    169.6.1.1       80:31380/TCP,443:31390/TCP,31400:31400/TCP    1m\n2d\n</code></pre> <ol> <li>Make note of the external IP address that you retrieved in the previous step, as it will be used to access the Guestbook app in later parts of the course. Create an environment variable called $INGRESS_IP with your IP address.</li> </ol> <p>Example:</p> <pre><code>export INGRESS_IP=169.6.1.1\n</code></pre>"},{"location":"exercise-5/#connect-istio-ingress-gateway-to-the-ibm-cloud-kubernetes-service-nlb-host-name","title":"Connect Istio Ingress Gateway to the IBM Cloud Kubernetes Service NLB Host Name","text":"<p>NLB host names are the DNS host names you can generate for each IBM Cloud Kubernetes deployment exposed with the Network LoadBalancer(NLB) service. These host names come with SSL certificate, the DNS registration, and health checks so you can benefit from them for any deployments that you expose via the NLB on IBM Cloud Kubernetes Service.</p> <p>You can run the IBM Cloud Kubernetes Service ALB, an API gateway of your choice, an Istio ingress gateway, and an MQTT server in parallel in your IBM Cloud Kubernetes Service cluster. Each one will have its own:</p> <pre><code>1. Publicly available wildcard host name\n2. Wildcard SSL certificate associated with the host name\n3. Health checks that you can configure if you use multizone deployments.\n</code></pre> <p>Let's leverage this feature with Istio ingress gateway:</p> <ol> <li> <p>Let's first check if you have any NLB host names for your cluster:</p> <pre><code>ibmcloud ks nlb-dnss --cluster $MYCLUSTER\n</code></pre> </li> </ol> <p>If you haven't used this feature before, you will get an empty list.</p> <ol> <li> <p>Obtain the Istio ingress gateway's external IP. Get the EXTERNAL-IP of the istio-ingressgateway service via output below:</p> <pre><code>kubectl get service istio-ingressgateway -n istio-system\n</code></pre> </li> <li> <p>Create the NLB host with the Istio ingress gateway's public IP address:</p> <pre><code>ibmcloud ks nlb-dns create classic --cluster $MYCLUSTER --ip $INGRESS_IP\n</code></pre> </li> <li> <p>List the NLB host names for your cluster:</p> <pre><code>ibmcloud ks nlb-dnss --cluster $MYCLUSTER\n</code></pre> <p>Example output:</p> <p><code>shell    Retrieving host names, certificates, IPs, and health check monitors for network load balancer (NLB) pods in cluster &lt;cluster_name&gt;... OK Hostname                                                                             IP(s)               Health Monitor   SSL Cert Status   SSL Cert Secret Name mycluster-85f044fc29ce613c264409c04a76c95d-0001.us-east.containers.appdomain.cloud   [\"169.1.1.1\"]       None             created           mycluster-85f044fc29ce613c264409c04a76c95d-0001</code></p> </li> <li> <p>Make note of the NLB host name (), as it will be used to access your Guestbook app in later parts of the course. Create an environment variable for it and test using curl or visit in your browser. <p>Example:</p> <pre><code>export NLB_HOSTNAME=mycluster-85f044fc29ce613c264409c04a76c95d-0001.us-east.containers.appdomain.cloud\n</code></pre> <pre><code>curl $NLB_HOSTNAME\n</code></pre> <li> <p>Enable health check of the NLB host for Istio ingress gateway:</p> <pre><code>ibmcloud ks nlb-dns monitor configure --cluster $MYCLUSTER --nlb-host $NLB_HOSTNAME --type HTTP --description \"Istio ingress gateway health check\" --path \"/healthz/ready\" --port 15021 --enable\n</code></pre> </li> <li> <p>Monitor the health check of the NLB host for Istio ingress gateway:</p> <pre><code>ibmcloud ks nlb-dns monitor status --cluster $MYCLUSTER\n</code></pre> <p>After waiting for a bit, you should start to see the health monitor's status changed to Enabled.</p> <p>Example output:</p> <pre><code>Retrieving health check monitor statuses for NLB pods...\nOK\nHostname                                                                             IP          Health Monitor   H.Monitor Status\nmycluster-85f044fc29ce613c264409c04a76c95d-0001.us-east.containers.appdomain.cloud   169.1.1.1   Enabled          Healthy\n</code></pre> </li> <p>Congratulations! You extended the base Ingress features by providing a DNS entry to the Istio service.</p>"},{"location":"exercise-5/#references","title":"References","text":"<ul> <li> <p>Kubernetes Ingress</p> </li> <li> <p>Istio Ingress</p> </li> <li> <p>Bring your own ALB</p> </li> </ul>"},{"location":"exercise-5/#continue-to-exercise-6-traffic-management","title":"Continue to Exercise 6 - Traffic Management","text":""},{"location":"exercise-6/","title":"Exercise 6 - Perform traffic management","text":""},{"location":"exercise-6/#using-rules-to-manage-traffic","title":"Using rules to manage traffic","text":"<p>The core component used for traffic management in Istio is Pilot, which manages and configures all the Envoy proxy instances deployed in a particular Istio service mesh. It lets you specify what rules you want to use to route traffic between Envoy proxies, which run as sidecars to each service in the mesh. Each service consists of any number of instances running on pods, containers, VMs etc. Each service can have any number of versions (a.k.a. subsets). There can be distinct subsets of service instances running different variants of the app binary. These variants are not necessarily different API versions. They could be iterative changes to the same service, deployed in different environments (prod, staging, dev, etc.). Pilot translates high-level rules into low-level configurations and distributes this config to Envoy instances. Pilot uses three types of configuration resources to manage traffic within its service mesh: Virtual Services, Destination Rules, and Service Entries.</p>"},{"location":"exercise-6/#virtual-services","title":"Virtual Services","text":"<p>A VirtualService defines a set of traffic routing rules to apply when a host is addressed. Each routing rule defines matching criteria for traffic of a specific protocol. If the traffic is matched, then it is sent to a named destination service (or subset or version of it) defined in the service registry.</p>"},{"location":"exercise-6/#destination-rules","title":"Destination Rules","text":"<p>A DestinationRule defines policies that apply to traffic intended for a service after routing has occurred. These rules specify configuration for load balancing, connection pool size from the sidecar, and outlier detection settings to detect and evict unhealthy hosts from the load balancing pool. Any destination <code>host</code> and <code>subset</code> referenced in a <code>VirtualService</code> rule must be defined in a corresponding <code>DestinationRule</code>.</p>"},{"location":"exercise-6/#service-entries","title":"Service Entries","text":"<p>A ServiceEntry configuration enables services within the mesh to access a service not necessarily managed by Istio. The rule describes the endpoints, ports and protocols of a white-listed set of mesh-external domains and IP blocks that services in the mesh are allowed to access.</p>"},{"location":"exercise-6/#the-guestbook-app","title":"The Guestbook app","text":"<p>In the Guestbook app, there is one service: guestbook. The guestbook service has two distinct versions: the base version (version 1) and the modernized version (version 2). Each version of the service has three instances based on the number of replicas in guestbook-deployment.yaml and guestbook-v2-deployment.yaml. By default, prior to creating any rules, Istio will route requests equally across version 1 and version 2 of the guestbook service and their respective instances in a round robin manner. However, new versions of a service can easily introduce bugs to the service mesh, so following A/B Testing and Canary Deployments is good practice.</p>"},{"location":"exercise-6/#ab-testing-with-istio","title":"A/B testing with Istio","text":"<p>A/B testing is a method of performing identical tests against two separate service versions in order to determine which performs better. To prevent Istio from performing the default routing behavior between the original and modernized guestbook service, define the following rules (found in istio101/workshop/plans):</p> <pre><code>kubectl create -f guestbook-destination.yaml\n</code></pre> <p>Let's examine the rule:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: destination-rule-guestbook\nspec:\n  host: guestbook\n  subsets:\n    - name: v1\n      labels:\n        version: '1.0'\n    - name: v2\n      labels:\n        version: '2.0'\n</code></pre> <p>Next, apply the VirtualService</p> <pre><code>kubectl replace -f virtualservice-all-v1.yaml\n</code></pre> <p>Let's examine the rule:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: virtual-service-guestbook\nspec:\n  hosts:\n    - '*'\n  gateways:\n    - guestbook-gateway\n  http:\n    - route:\n        - destination:\n            host: guestbook\n            subset: v1\n</code></pre> <p>The <code>VirtualService</code> defines a rule that captures all HTTP traffic coming in through the Istio ingress gateway, <code>guestbook-gateway</code>, and routes 100% of the traffic to pods of the guestbook service with label \"version: v1\". A subset or version of a route destination is identified with a reference to a named service subset which must be declared in a corresponding <code>DestinationRule</code>. Since there are three instances matching the criteria of hostname <code>guestbook</code> and subset <code>version: v1</code>, by default Envoy will send traffic to all three instances in a round robin manner.</p> <p>View the guestbook application using the <code>$NLB_HOSTNAME</code> specified in Exercise 5 and enter it as a URL in Firefox or Chrome web browsers. You can use the echo command to get this value, if you don't remember it.</p> <pre><code>echo $NLB_HOSTNAME\n</code></pre> <p>To enable the Istio service mesh for A/B testing against the new service version, modify the original <code>VirtualService</code> rule:</p> <pre><code>kubectl replace -f virtualservice-test.yaml\n</code></pre> <p>Let's examine the rule:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: virtual-service-guestbook\nspec:\n  hosts:\n    - '*'\n  gateways:\n    - guestbook-gateway\n  http:\n    - match:\n        - headers:\n            user-agent:\n              regex: '.*Firefox.*'\n      route:\n        - destination:\n            host: guestbook\n            subset: v2\n    - route:\n        - destination:\n            host: guestbook\n            subset: v1\n</code></pre> <p></p> <p>In Istio <code>VirtualService</code> rules, there can be only one rule for each service and therefore when defining multiple HTTPRoute blocks, the order in which they are defined in the yaml matters. Hence, the original <code>VirtualService</code> rule is modified rather than creating a new rule. With the modified rule, incoming requests originating from <code>Firefox</code> browsers will go to the newer version of guestbook. All other requests fall-through to the next block, which routes all traffic to the original version of guestbook.</p>"},{"location":"exercise-6/#canary-deployment","title":"Canary deployment","text":"<p>In <code>Canary Deployments</code>, newer versions of services are incrementally rolled out to users to minimize the risk and impact of any bugs introduced by the newer version. To begin incrementally routing traffic to the newer version of the guestbook service, modify the original <code>VirtualService</code> rule:</p> <pre><code>kubectl replace -f virtualservice-80-20.yaml\n</code></pre> <p>Let's examine the rule:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: virtual-service-guestbook\nspec:\n  hosts:\n    - '*'\n  gateways:\n    - guestbook-gateway\n  http:\n    - route:\n        - destination:\n            host: guestbook\n            subset: v1\n          weight: 80\n        - destination:\n            host: guestbook\n            subset: v2\n          weight: 20\n</code></pre> <p>In the modified rule, the routed traffic is split between two different subsets of the guestbook service. In this manner, traffic to the modernized version 2 of guestbook is controlled on a percentage basis to limit the impact of any unforeseen bugs. This rule can be modified over time until eventually all traffic is directed to the newer version of the service.</p> <p>View the guestbook application using the <code>$NLB_HOSTNAME</code> specified in Exercise 5 and enter it as a URL in Firefox or Chrome web browsers. Ensure that you are using a hard refresh (command + Shift + R on Mac or Ctrl + F5 on windows) to remove any browser caching. You should notice that the guestbook should swap between V1 or V2 at about the weight you specified.</p>"},{"location":"exercise-6/#route-all-traffic-to-v2","title":"Route all traffic to v2","text":"<p>For the following exercises, we'll be working with Guestbook v2. Route all traffic to guestbook v2 with a new VirtualService rule:</p> <pre><code>cat &lt;&lt;EOF | kubectl replace -f -\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: virtual-service-guestbook\nspec:\n  hosts:\n    - '*'\n  gateways:\n    - guestbook-gateway\n  http:\n    - route:\n        - destination:\n            host: guestbook\n            subset: v2\nEOF\n</code></pre>"},{"location":"exercise-6/#implementing-circuit-breakers-with-destination-rules","title":"Implementing circuit breakers with destination rules","text":"<p>Istio <code>DestinationRules</code> allow users to configure Envoy's implementation of circuit breakers. Circuit breakers are critical for defining the behavior for service-to-service communication in the service mesh. In the event of a failure for a particular service, circuit breakers allow users to set global defaults for failure recovery on a per service and/or per service version basis. Users can apply a traffic policy at the top level of the <code>DestinationRule</code> to create circuit breaker settings for an entire service, or it can be defined at the subset level to create settings for a particular version of a service.</p> <p>Depending on whether a service handles HTTP requests or TCP connections, <code>DestinationRules</code> expose a number of ways for Envoy to limit traffic to a particular service as well as define failure recovery behavior for services initiating the connection to an unhealthy service.</p>"},{"location":"exercise-6/#further-reading","title":"Further reading","text":"<ul> <li>Istio Concept</li> <li>Istio Rules API</li> <li>Istio Proxy Debug Tool</li> <li>Traffic Management</li> <li>Circuit Breaking</li> <li>Timeouts and Retries</li> </ul>"},{"location":"exercise-6/#questions","title":"Questions","text":"<ol> <li>Where are routing rules defined?  Options: (VirtualService, DestinationRule, ServiceEntry)  Answer: VirtualService</li> <li>Where are service versions (subsets) defined?  Options: (VirtualService, DestinationRule, ServiceEntry)  Answer: DestinationRule</li> <li>Which Istio component is responsible for sending traffic management configurations to Istio sidecars?  Options: (Mixer, Citadel, Pilot, Kubernetes)  Answer: Pilot</li> <li>What is the name of the default proxy that runs in Istio sidecars and routes requests within the service mesh?  Options: (NGINX, Envoy, HAProxy)  Answer: Envoy</li> </ol>"},{"location":"exercise-6/#continue-to-exercise-7-security","title":"Continue to Exercise 7 - Security","text":""},{"location":"exercise-7/","title":"Exercise 7 - Secure your services","text":""},{"location":"exercise-7/#mutual-authentication-with-transport-layer-security-mtls","title":"Mutual authentication with Transport Layer Security (mTLS)","text":"<p>Istio can secure the communication between microservices without requiring application code changes. Security is provided by authenticating and encrypting communication paths within the cluster. This is becoming a common security and compliance requirement. Delegating communication security to Istio (as opposed to implementing TLS in each microservice), ensures that your application will be deployed with consistent and manageable security policies.</p> <p>Istio Citadel is an optional part of Istio's control plane components. When enabled, it provides each Envoy sidecar proxy with a strong (cryptographic) identity, in the form of a certificate. Identity is based on the microservice's service account and is independent of its specific network location, such as cluster or current IP address. Envoys then use the certificates to identify each other and establish an authenticated and encrypted communication channel between them.</p> <p>Citadel is responsible for:</p> <ul> <li> <p>Providing each service with an identity representing its role.</p> </li> <li> <p>Providing a common trust root to allow Envoys to validate and authenticate each other.</p> </li> <li> <p>Providing a key management system, automating generation, distribution, and rotation of certificates and keys.</p> </li> </ul> <p>When an application microservice connects to another microservice, the communication is redirected through the client side and server side Envoys. The end-to-end communication path is:</p> <ul> <li> <p>Local TCP connection (i.e., <code>localhost</code>, not reaching the \"wire\") between the application and Envoy (client- and server-side);</p> </li> <li> <p>Mutually authenticated and encrypted connection between Envoy proxies.</p> </li> </ul> <p>When Envoy proxies establish a connection, they exchange and validate certificates to confirm that each is indeed connected to a valid and expected peer. The established identities can later be used as basis for policy checks (e.g., access authorization).</p>"},{"location":"exercise-7/#enforce-mtls-between-all-istio-services","title":"Enforce mTLS between all Istio services","text":"<ol> <li>To enforce a mesh-wide authentication policy that requires mutual TLS, submit the following policy. This policy specifies that all workloads in the mesh will only accept encrypted requests using TLS.</li> </ol> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: \"security.istio.io/v1beta1\"\nkind: \"PeerAuthentication\"\nmetadata:\n  name: \"default\"\n  namespace: \"istio-system\"\nspec:\n  mtls:\n    mode: STRICT\nEOF\n</code></pre> <ol> <li>Visit your guestbook application by going to it in your browser. Everything should be working as expected! To confirm mTLS is infact enabled, you can run:</li> </ol> <pre><code>istioctl x describe service guestbook\n</code></pre> <p>Example output:</p> <pre><code>Service: guestbook\n  Port: http 80/HTTP targets pod port 3000\nDestinationRule: destination-rule-guestbook for \"guestbook\"\n  Matching subsets: v1,v2\n  No Traffic Policy\nPod is STRICT, clients configured automatically\n</code></pre>"},{"location":"exercise-7/#configure-access-control-for-workloads-using-http-traffic","title":"Configure access control for workloads using HTTP traffic","text":"<ol> <li> <p>Modify guestbook and analyzer deployments to use leverage the service accounts.</p> <ul> <li>Navigate to your guestbook dir first, for example:</li> </ul> <pre><code>cd ../guestbook\n</code></pre> <ul> <li>Add serviceaccount to your guestbook and analyzer deployments</li> </ul> <pre><code>echo \"      serviceAccountName: guestbook\" &gt;&gt; v1/guestbook-deployment.yaml\necho \"      serviceAccountName: guestbook\" &gt;&gt; v2/guestbook-deployment.yaml\necho \"      serviceAccountName: analyzer\" &gt;&gt; v2/analyzer-deployment.yaml\n</code></pre> <ul> <li>redeploy the guestbook and analyzer deployments</li> </ul> <pre><code>kubectl replace -f v1/guestbook-deployment.yaml\nkubectl replace -f v2/guestbook-deployment.yaml\nkubectl replace -f v2/analyzer-deployment.yaml\n</code></pre> </li> <li> <p>Create a <code>AuthorizationPolicy</code> to disable all access to analyzer service.  This will effectively not allow guestbook or any services to access it.</p> </li> </ol> <pre><code>cat &lt;&lt;EOF | kubectl create -f -\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: analyzeraccess\nspec:\n  selector:\n    matchLabels:\n      app: analyzer\nEOF\n</code></pre> <p>Output:</p> <pre><code>authorizationpolicy.security.istio.io/analyzeraccess created\n</code></pre> <ol> <li> <p>Visit the Guestbook app from your favorite browser and validate that Guestbook V1 continues to work while Guestbook V2 will not run correctly. For every new message you write on the Guestbook v2 app, you will get a message such as \"Error - unable to detect Tone from the Analyzer service\".  It can take up to 15 seconds for the change to propogate to the envoy sidecar(s) so you may not see the error right away.</p> </li> <li> <p>Configure the Analyzer service to only allow access from the Guestbook service using the added <code>rules</code> section:</p> </li> </ol> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: analyzeraccess\nspec:\n  selector:\n    matchLabels:\n      app: analyzer\n  rules:\n  - from:\n    - source:\n        principals: [\"cluster.local/ns/default/sa/guestbook\"]\n    to:\n    - operation:\n        methods: [\"POST\"]\nEOF\n</code></pre> <ol> <li>Visit the Guestbook app from your favorite browser and validate that Guestbook V2 works now.  It can take a few seconds for the change to propogate to the envoy sidecar(s) so you may not observe Guestbook V2 to function right away.</li> </ol>"},{"location":"exercise-7/#cleanup","title":"Cleanup","text":"<p>Run the following commands to clean up the Istio configuration resources as part of this exercise:</p> <pre><code>kubectl delete PeerAuthentication default\nkubectl delete dr default\nkubectl delete dr destination-rule-guestbook\nkubectl delete sa guestbook analyzer\nkubectl delete AuthorizationPolicy analyzeraccess\n</code></pre>"},{"location":"exercise-7/#quiz","title":"Quiz","text":"<p>True or False?</p> <ol> <li> <p>Istio Citadel provides each microservice with a strong, cryptographic, identity in the form of a certificate. The certificates' life cycle is fully managed by Istio. (True)</p> </li> <li> <p>Istio provides microservices with mutually authenticated connections, without requiring app code changes. (True)</p> </li> <li> <p>Mutual authentication must be on or off for the entire cluster, gradual adoption is not possible. (False)</p> </li> </ol>"},{"location":"exercise-7/#further-reading","title":"Further Reading","text":"<ul> <li> <p>Basic TLS/SSL Terminology</p> </li> <li> <p>TLS Handshake Explained</p> </li> <li> <p>Istio Task</p> </li> <li> <p>Istio Concept</p> </li> </ul>"}]}